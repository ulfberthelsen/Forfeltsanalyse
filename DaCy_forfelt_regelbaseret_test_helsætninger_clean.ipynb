{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd96350a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download da_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179bb3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "from spacy import displacy\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d554f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"da_core_news_lg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96155280",
   "metadata": {},
   "source": [
    "### Teksteksempel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19688111",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = nlp(\"Mette er single, men vil gerne have en kæreste. Mette er sporty, og hun cykler meget. Mette og Marie er venner. Mette, der er 24 år, læser på AU. Hun bor i Aarhus. Aarhus, som har mange uddannelsesinstitutioner, har mange studerende. Fordi hun studerer, bor hun på kollegium. Hun skal heldigvis have ferie, når hun har været til eksamen. Efter ferien skal hun tilbage på universitetet. Hvis hun er holder planen, er hun færdig om to år. På mandag skal hun til tandlægen. Bagefter skal hun hjem og se netflix. På tirsdag skal hun blive hjemme. Det skal hun også på onsdag. Fordi de sad og snakkede, kom de for sent til bussen. Aarhus' førende idrætsforening har mange medlemmer. Det er ikke fordi, jeg ikke kan lide dig, sagde han. Manden, som har mange venner, bor i Aarhus \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16841c5",
   "metadata": {},
   "source": [
    "# Forfelt som string + gennemsnitslængde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d48069",
   "metadata": {},
   "outputs": [],
   "source": [
    "### denne funktion returnerer en liste med forfeltet for sætning som string\n",
    "def forfelt_string(nlpobject):\n",
    "    forfeltStr = [] # liste med forfeltet som string for hver sætning i teksten\n",
    "    for id, s in enumerate(nlpobject.sents):# enumerate() giver hver sætning et id-nummer\n",
    "        vid = [] #liste til verbernes id-nummer\n",
    "        for i,w in enumerate(s):#denne sekvens identificerer de finitte verbums id-nummer for hver sætning\n",
    "            if w.dep_== \"AUX\" and w.head.dep_ == \"ROOT\": #hvis V1 = hjælpeverbum\n",
    "                vid.append(i)\n",
    "            elif w.pos_ == \"VERB\" and w.dep_ == \"ROOT\" and \"AUX\" not in [child.dep_ for child in w.children]: #hvis V1 er hovedverbet\n",
    "                vid.append(i)\n",
    "            elif w.pos_== \"AUX\" and w.dep_ == \"COP\" and w.head.dep_ != \"acl:relcl\": #sorterer relativ ledsætninger med 'er' fra\n",
    "                vid.append(i)\n",
    "            elif w.pos_== \"AUX\" and w.head.pos_ == \"ADV\": #usikker - eks: \"bagefter skal hun hjem\"\n",
    "                vid.append(i)\n",
    "            elif w.pos_== \"AUX\" and w.head.dep_ == \"ROOT\": # inkluderer tilfælde, hvor 'skal' ikke ikke følges af hovedverbum og derfor er root\n",
    "                vid.append(i)\n",
    "        forfelt = [] # laver en liste for hver sætning med de nlpObjekt-tokens, der hører til forfeltet\n",
    "        for i,w in enumerate(s):\n",
    "            if len(vid) > 0:# hvis(for hver sætning) listen  med verbernes id ikke e tom\n",
    "                fvi = vid[0] #så er det finitte verbums id-nummer, det første id-nummer på listen\n",
    "                if i < fvi:# hvis et ords id-nummer er lavere end det finitte verbums id-nummer\n",
    "                    forfelt.append(w) # så tilføjes dette nlpObject-token til listen\n",
    "        forfelt_ord = []\n",
    "        for w in forfelt:\n",
    "            forfelt_ord.append(w.text)\n",
    "        lst = \" \".join(forfelt_ord)\n",
    "        forfeltStr.append(lst) \n",
    "    return(forfeltStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71d767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Denne funktion returnerer det gennemsnitlige antal ord for en teksts forfelter\n",
    "def meanLenForf(nlpobject):\n",
    "    strings = forfelt_string(nlpobject)\n",
    "    stringsClean = [s.replace(\",\", \" \") for s in strings]\n",
    "    lenForf = [len(s.split()) for s in stringsClean]\n",
    "    gennemsnit = sum(lenForf) / len(lenForf)\n",
    "    return(gennemsnit)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfda4bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### denne funktion returnerer en liste med forfeltets dep-tag for sætning som string\n",
    "def forfelt_dep(nlpobject):\n",
    "    forfeltStr = [] # liste med forfeltet som string for hver sætning i teksten\n",
    "    for id, s in enumerate(nlpobject.sents):# enumerate() giver hver sætning et id-nummer\n",
    "        vid = [] #liste til verbernes id-nummer\n",
    "        for i,w in enumerate(s):#denne sekvens identificerer de finitte verbums id-nummer for hver sætning\n",
    "            if w.dep_== \"AUX\" and w.head.dep_ == \"ROOT\": #hvis V1 = hjælpeverbum\n",
    "                vid.append(i)\n",
    "            elif w.pos_ == \"VERB\" and w.dep_ == \"ROOT\" and \"AUX\" not in [child.dep_ for child in w.children]: #hvis V1 er hovedverbet\n",
    "                vid.append(i)\n",
    "            elif w.pos_== \"AUX\" and w.dep_ == \"COP\" and w.head.dep_ != \"acl:relcl\": #sorterer relativ ledsætninger med 'er' fra\n",
    "                vid.append(i)\n",
    "            elif w.pos_== \"AUX\" and w.head.pos_ == \"ADV\": #usikker - eks: \"bagefter skal hun hjem\"\n",
    "                vid.append(i)\n",
    "            elif w.pos_== \"AUX\" and w.head.dep_ == \"ROOT\": # inkluderer tilfælde, hvor 'skal' ikke ikke følges af hovedverbum og derfor er root\n",
    "                vid.append(i)\n",
    "        forfelt = [] # laver en liste for hver sætning med de nlpObjekt-tokens, der hører til forfeltet\n",
    "        for i,w in enumerate(s):\n",
    "            if len(vid) > 0:# hvis(for hver sætning) listen  med verbernes id ikke e tom\n",
    "                fvi = vid[0] #så er det finitte verbums id-nummer, det første id-nummer på listen\n",
    "                if i < fvi:# hvis et ords id-nummer er lavere end det finitte verbums id-nummer\n",
    "                    forfelt.append(w) # så tilføjes dette nlpObject-token til listen\n",
    "        forfelt_ord = []\n",
    "        for w in forfelt:\n",
    "            forfelt_ord.append(w.dep_)\n",
    "        lst = \" \".join(forfelt_ord)\n",
    "        forfeltStr.append(lst) \n",
    "    return(forfeltStr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b745ad46",
   "metadata": {},
   "source": [
    "### Eksempler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c999f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "forfelt_dep(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debef746",
   "metadata": {},
   "outputs": [],
   "source": [
    "forfelt_string(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2273e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnmstForf = meanLenForf(txt)\n",
    "print(gnmstForf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2018dbf",
   "metadata": {},
   "source": [
    "# Forfelt som Spacy-tags + ordklasseratio for felterne i en tekst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d946566",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Denne function returnerer en liste med lister af spacy-tokens for hvert forfelt i en tekst\n",
    "def forfelt_tokNLP(nlpobject):\n",
    "    forfelt_info = []\n",
    "    for id, s in enumerate(nlpobject.sents):# enumerate() giver hver sætning et id-nummer\n",
    "        vid = [] #liste til verbernes id-nummer\n",
    "        for i,w in enumerate(s):#denne sekvens identificerer de finitte verbums id-nummer for hver sætning\n",
    "            if w.dep_== \"aux\" and w.head.dep_ == \"ROOT\": #hvis V1 = hjælpeverbum\n",
    "                vid.append(i)\n",
    "            elif w.pos_ == \"VERB\" and w.dep_ == \"ROOT\" and \"aux\" not in [child.dep_ for child in w.children]: #hvis V1 er hovedverbet\n",
    "                vid.append(i)\n",
    "            elif w.pos_== \"AUX\" and w.dep_ == \"cop\" and w.head.dep_ != \"acl:relcl\": #sorterer relativ ledsætninger med 'er' fra\n",
    "                vid.append(i)\n",
    "            elif w.pos_== \"AUX\" and w.head.pos_ == \"ADV\": #usikker - eks: \"bagefter skal hun hjem\"\n",
    "                vid.append(i)\n",
    "            elif w.pos_== \"AUX\" and w.head.dep_ == \"ROOT\": # inkluderer tilfælde, hvor 'skal' ikke ikke følges af hovedverbum og derfor er root\n",
    "                vid.append(i)\n",
    "        forfelt = [] # laver en liste for hver sætning med de nlpObjekt-tokens, der hører til forfeltet\n",
    "        for i,w in enumerate(s):\n",
    "            if len(vid) > 0:# hvis(for hver sætning) listen  med verbernes id ikke e tom\n",
    "                fvi = vid[0] #så er det finitte verbums id-nummer, det første id-nummer på listen\n",
    "                if i < fvi:# hvis et ords id-nummer er lavere end det finitte verbums id-nummer\n",
    "                    forfelt.append(w) # så tilføjes dette nlpObject-token til listen\n",
    "        forfelt_info.append(forfelt) \n",
    "    return(forfelt_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44e1927",
   "metadata": {},
   "outputs": [],
   "source": [
    "### denne funktion returnerer en dictionary med en optaælling af det samlede antal POS-tags i en teksts forfelter\n",
    "def freqPosForf(nlpobject):\n",
    "    forfRaw = forfelt_tokNLP(txt) #returnerer en liste med lister af spacy-tokens for hvert forfelt i en tekst\n",
    "    txtPosTags = [] # følgende sekvens danner en liste med det samlede antal POS-tags for tekstens forfelter\n",
    "    for f in forfRaw:\n",
    "        for t in f:\n",
    "            if t.pos_ != \"PUNCT\":\n",
    "                txtPosTags.append(t.pos_)\n",
    "    counter = {}\n",
    "    for tag in txtPosTags:\n",
    "        if tag not in counter:\n",
    "            counter[tag] = 0\n",
    "        counter[tag] += 1\n",
    "    return(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1205f817",
   "metadata": {},
   "outputs": [],
   "source": [
    "forfelt_tokNLP(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd466cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqPosForf(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59d00dc",
   "metadata": {},
   "source": [
    "# Pie chats POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b91a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c11984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "posDict = freqPosForf(txt)\n",
    "posDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b05b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "posDict_2 = {'PROPN': 2,\n",
    " 'ADV': 2,\n",
    " 'AUX': 2,\n",
    " 'NUM': 1,\n",
    " 'NOUN': 6,\n",
    " 'PRON': 6,\n",
    " 'VERB': 3,\n",
    " 'ADJ': 1,\n",
    " 'SCONJ': 2,\n",
    " 'ADP': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8b2354",
   "metadata": {},
   "outputs": [],
   "source": [
    "### denne funktion returnerer en dictionary med en optaælling af det samlede antal dep-tags i en teksts forfelter\n",
    "def freqDepForf(nlpobject):\n",
    "    forfRaw = forfelt_tokNLP(txt) #returnerer en liste med lister af spacy-tokens for hvert forfelt i en tekst\n",
    "    txtPosTags = [] # følgende sekvens danner en liste med det samlede antal POS-tags for tekstens forfelter\n",
    "    for f in forfRaw:\n",
    "        for t in f:\n",
    "            if t.pos_ != \"PUNCT\":\n",
    "                txtPosTags.append(t.dep_)\n",
    "    counter = {}\n",
    "    for tag in txtPosTags:\n",
    "        if tag not in counter:\n",
    "            counter[tag] = 0\n",
    "        counter[tag] += 1\n",
    "    return(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402c59b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqDepForf(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70da9c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in txt.sents:\n",
    "    print(s.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c34332",
   "metadata": {},
   "source": [
    "# Merger dictionaries, så de kan plottes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e72de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_1 = Counter(posDict)\n",
    "d_2 = Counter(posDict_2)\n",
    "posDict_3 = dict(d_1 + d_2) # gør counteren til en dictionary, så den kan plottes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d35c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "posDict_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d4f3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "your_data = {\n",
    "    'PROPN': 2,\n",
    "    'ADV': 2,\n",
    "    'AUX': 2,\n",
    "    'NUM': 1,\n",
    "    'NOUN': 6,\n",
    "    'PRON': 6,\n",
    "    'VERB': 3,\n",
    "    'ADJ': 1,\n",
    "    'SCONJ': 2,\n",
    "    'ADP': 3}\n",
    "\n",
    "\n",
    "# Data to plot\n",
    "labels = []\n",
    "sizes = []\n",
    "\n",
    "for x, y in your_data.items():\n",
    "    labels.append(x)\n",
    "    sizes.append(y)\n",
    "\n",
    "# Plot\n",
    "plt.pie(sizes, labels = labels, autopct='%1.1f%%')\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf59820b",
   "metadata": {},
   "source": [
    "# Dependency trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d898019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_spans = list(txt.sents)\n",
    "options = {\"compact\": True}\n",
    "displacy.render(sentence_spans, style=\"dep\", options=options)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
